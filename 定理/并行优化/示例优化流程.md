Scan

https://github.com/ArchaeaSoftware/cudahandbook

CPU版

```
template<class T>
T InclusiveScan(T *out,const T *in, size_t N)
{
	T sum(0);
	for(size_t i = 0;i < N;i++)
	{
		sum += in[i];
		out[i] = sum;
	}
	return sum;
}
```

GPU版本scan then fan

```
template<class T>
inline __device__ T
scanBlock(volatile T * sPartilas)
{
	extern __shared__ T warpPartials[];
	const int tid = threadIdx.x;
	const int lane = tid & 31;
	const int warpid = tid >> 5;
	// compute this thread`s partial sum
	T sum = scanWarp<T>(sPartials);
	__syncthreads();
	// write each warp`s reduction to shared memory
	if(lane == 31)
	{warpPartials[16 + warpid] = sum;}
	__syncthreads();
	// have one warp scan reductions
	if(warpid == 0)
	{scanWarp<T>(16 + warpPartials+tid);}
	__syncthreads();
}
```



### 支线：zeropadding

在数组前添加16个零，来减少if的数量

优化前

```
template<class T>
inline __device__ T
scanWarp( volatile T *sPartials )
{
const int tid = threadIdx.x;
const int lane = tid & 31;
if ( lane >= 1 ) sPartials[0] += sPartials[- 1];
if ( lane >= 2 ) sPartials[0] += sPartials[- 2];
if ( lane >= 4 ) sPartials[0] += sPartials[- 4];
if ( lane >= 8 ) sPartials[0] += sPartials[- 8];
if ( lane >= 16 ) sPartials[0] += sPartials[-16];
return sPartials[0];
}
```

优化后

```
template<class T>
__device__ T scanWarp0( volatile T *sharedPartials, int idx )
{
const int tid = threadIdx.x;
const int lane = tid & 31;
sharedPartials[idx] += sharedPartials[idx - 1];
sharedPartials[idx] += sharedPartials[idx - 2];
sharedPartials[idx] += sharedPartials[idx - 4];
sharedPartials[idx] += sharedPartials[idx - 8];
sharedPartials[idx] += sharedPartials[idx - 16];
return sharedPartials[idx];
}
```

